---
title: "Eye tracking Workshop CogSci F2021"
subtitle: "Data analysis exercise"
author: "Fabio Trecca"
date: "3/5/2021"
output: html_document
---

```{r setup, include=FALSE}
require(knitr)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
pacman::p_load(tidyverse, jpeg, grid, lme4, lmerTest, DHARMa, MuMIn, bayesplot, brms, rethinking,ggplot2,hrbrthemes,dplyr,tidyr,viridis)

```

## Load the data if necessary

```{r load data}
## We need the guess_max = Inf here, even though this will make the file loading slower
Fixations <- read_csv("/Users/pernillebrams/Desktop/UNI/4th semester/SocKultExam/Eye-Tracking-Workhop-CogSci-F2021/data/Fixations_final.csv", guess_max = Inf)

Saccades <- read_csv("/Users/pernillebrams/Desktop/UNI/4th semester/SocKultExam/Eye-Tracking-Workhop-CogSci-F2021/data/Saccades_final.csv")
```

## Visual foraging (Rhodes et al., 2014)

We want to test the hypothesis that eye movements are affected by task structure and goals (top-down influence): i.e., eye movements differ based on whether we are searching for the start or counting objects, *even when we are looking at the same pictures*.

### Hypothesis 1: Longer tail for saccades amplitude in Search (vs Count) condition

We know from the paper that the amplitude of saccades in the searching task has a peculiar frequency distribution with a long tail. This means that most of the saccades have very short amplitued, but few of them have very high amplitude (since our eyes are "hopping" to a new place where we can forage). The same may not be true for the counting task, where we expect there to be less variation in the amplitude of saccades (thus a shorter tail). 

Let's start by testing this hypothesis. First of all we plot the density distribution of saccade amplitudes in the two tasks:

```{r}
# Plotting density distribution of saccade amplitudes in the two tasks
Saccades_VF <- Saccades %>% filter(Saccades$Task == "Visual foraging")
Saccades_SE <- Saccades %>% filter(Saccades$Task == "Social engagement")

# First look 
par(mfrow = c(1,2))
dens(Saccades_VF$Amplitude)+title("Saccade Amp., Density dist. 
Task: Visual Foraging")
dens(Saccades_SE$Amplitude)+title("Saccade Amp., Density dist.
Task: Social Engagement")

# We know from the Rhodes paper that the amplitude of saccades in the search task has a certain frequency distribution with a long tail. This means that most of the saccades have a very short amplitude, but few have a high - since our eyes hop to new places where we can forage. The same may not be true for the counting task, where we expect there to be less variation in the amplitude of saccades - so a shorter tail in the count condition. Search or Count - With transparency plotted here - 
# We expect:  Long tail for saccades amplitude in Search (vs Count) condition.
VF <- ggplot(data=Saccades_VF, aes(x=Amplitude, group=SearchOrCount, fill=SearchOrCount)) +
    geom_density(adjust=1.5, alpha=.4) +
    theme_ipsum()+ggtitle("Search or Count in Visual Foraging, amplitudes plotted")
VF
```

The plot seems to show that searching has a thin head and a long tail, whereas the opposite is true of counting.

Let's model the data. Start by trying to figure out how the data are distributed. We will first make a gaussian model for baseline, which we know doesn't make sense given what the data looks like. Find the fixed and random effect structure that you think is most appropriate.

Note: m_HR <- lmerTest::lmer(change_HR_self ~ 0 + (HR_self + HR_diff):Condition + (0 + Condition|Participant) + (0 + Condition|Group), data = dfmerge %>% filter(Type == "Original"), control = lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))

```{r}

```

We can then try modelling the data with a lognormal distribution, which seems more appropriate to our data. (Notice that for the lognormal model to work, Amplitude should be different from zero -- please fix if necessary).

```{r}
# NA-omit
Saccades_VF <- Saccades_VF %>% na.omit()
Saccades_VF <- Saccades_VF %>% filter(Amplitude > 0)
Saccades_VF$LogAmplitude <- log(Saccades_VF$Amplitude)
```


```{r}
#Fabio way

mGaus <- 
  glmer(
    Amplitude ~ SearchOrCount + 
      (1 + SearchOrCount | ParticipantID)+ # The average saccade amplitude changes per Participant, and per stimulus, and they VARY in the two conditions (SearchOrCount as slope)
      (1 + SearchOrCount | Stimulus),
    family = gaussian(link = "identity"),
    data = Saccades_VF
  )

summary(mGaus)

mLog <- 
  glmer(
    Amplitude ~ SearchOrCount + 
      (1 + SearchOrCount | ParticipantID)+ 
      (1 + SearchOrCount | Stimulus),
    family = gaussian(link = "log"),
    data = Saccades_VF
  )

summary(mLog)

```
The mean amplitude in the Search condition is significantly higher, which is consistent with the plot. But which model is the best one? Generate predictions from the models and plot their density, then compare the predictions to the distribution of the actual data. What do you notice?

```{r}
pm1 <- predict(mGaus)
pm2 <- predict(mLog)

par(mfrow=c(1,3))
plot(density(pm1), main = "Gaussian")
plot(density(pm2), main = "Log-transformed")

plot(density(Saccades$Amplitude), main = "Observed saccade amplitude")
plot(density(Saccades_VF$Amplitude), main = "Observed saccade amplitude")
plot(density(Saccades_SE$Amplitude), main = "Observed saccade amplitude")

plot(density(log(Saccades$Amplitude)), main = "Observed saccade amplitude")

```


Numericaly compare the model predictions to the actual data (in absolute values) in order to get an idea of how well the model predicts the data:

```{r}
summary(abs(pm1-Saccades_VF$Amplitude))
summary(abs(pm2-Saccades_VF$Amplitude))
```

We can compare observed data and model predictions more formally by looking at the residuals of the fitted models. To do this, we use the DHARMa (residual Diagnostics for HierArchical Regression Models) package:

```{r}
# first we use the simulateResiduals() function to compute the (scaled) residuals of the fitted model
# n = 250 is the number of simulations that we want DHARMa to run
dGaus <- simulateResiduals(mGaus, n = 250)
dLog <- simulateResiduals(mLog, n = 250)
```

Now we can plot the residuals for the gaussian and lognormal models and see which model does best. Do we notice any  differences? Is one model doing better than the other?

```{r}
plot(dGaus)
plot(dLog)

plot(density(dGaus$scaledResiduals))
plot(density(dLog$scaledResiduals))

```

Lastly, we can use the r.squaredGLMM() function from the MuMIn (Multi-Model Inference) package in order to calculate conditional and marginal R^2 of the two models to get a measure of their goodness of fit. Which model provides the best fit to the data?

```{r}
r.squaredGLMM(mGaus) # R2m: 0.07355488 R2c: 0.1085559
r.squaredGLMM(mLog) #R2m: 0.09627207 R2c: 0.134115

anova(mGaus, mLog)
AIC(mGaus, mLog)

```

We can confirm these results by simply counting the number of very long saccades in the two conditions. One way of operationalize this may be to define a "Long" saccade as one that is above 2 SD from the mean, and a "Short" saccade as one that is below 2 SD from the mean. You can code "Long" as 1 and "Short" as 0.

```{r}
Saccades_VF$Amplitude_scaled <- scale(Saccades_VF$Amplitude, center = TRUE, scale = TRUE)

Saccades_VF$LongSaccade <- ifelse(Saccades_VF$Amplitude_scaled > 2, 1, ifelse(Saccades_VF$Amplitude_scaled < 2, 0, NA)) %>% as.factor()

```

Using logistic regression, test the predictions that the probability of saccade amplitude being long is higher in the Search condition than in the Count condition:

```{r}
## Table the data first
table(
  Saccades_VF[Saccades_VF$Task == "Visual foraging", ]$LongSaccade,
  Saccades_VF[Saccades_VF$Task == "Visual foraging", ]$SearchOrCount
  )

# Just to some factoring
Saccades_VF$SearchOrCount <- as.factor(Saccades_VF$SearchOrCount)

mLogit <- glmer(LongSaccade ~ 0 + SearchOrCount + 
                  (0 + SearchOrCount|ParticipantID) + 
                  (0 + SearchOrCount|Stimulus), 
                Saccades_VF, family = binomial)

summary(mLogit)

# probability for estimate of intercept (the probability of LongSaccade given that you are in Count-mode.. )
boot::inv.logit(-4.0669) # 0.01%

# probability for estimate of going from first level to second level in the "SearchOrCount" variable, i.e. from count to search condition. The significant p-value for this estimate suggests that being in search mode instead of count mode significantly affects the probability of having a long saccade.
boot::inv.logit(-2.7208) # 6%


```

What does this model show?

### Hypothesis 2: Longer fixation duration in Count (vs Search) condition

We can imagine that people make slightly longer fixations when counting objects rather than searching for the star. Visual foraging is usually associated with faster movements, so maybe we will see a difference here.

Let's start by plotting fixation duration in the two conditions:

```{r}
par(mfrow=c(1,2))
plot(density(Fixations[Fixations$Task == "Visual foraging" &
                 Fixations$SearchOrCount == "Search", ]$Duration), main = "Search")
plot(density(Fixations[Fixations$Task == "Visual foraging" &
                 Fixations$SearchOrCount == "Count", ]$Duration), main = "Count")
```

What do the plots seem to show? Do they corroborate our hypothesis?

Let's test this statistically as well. We will take the same approach as above by running a Gaussian model first, and a Log-normal model afterward.

```{r}
mGaus <-
  glmer(
    Duration ~ SearchOrCount + 
      (1 + SearchOrCount | ParticipantID) + 
      (1 + SearchOrCount | Stimulus),
    family = gaussian(link = "identity"),
    data = Fixations
  )

mLog <-
  glmer(
    Duration ~ SearchOrCount + 
      (1 + SearchOrCount | ParticipantID) + 
      (1 + SearchOrCount | Stimulus),
    family = gaussian(link = "log"),
    data = Fixations
  )

summary(mGaus)
summary(mLog)
```

If the fit is singular, do a step-wise reduction of the random effect structure (random slopes first and random intercepts last if necessary).

What do the models show? And which model is the best fit to the data? Generate predictions from the models and plot their density, then compare the predictions to the distribution of the actual data.

```{r}
pm1 <- predict(mGaus)
pm2 <- predict(mLog)

par(mfrow=c(1,3))
plot(density(pm1), main = "Gaussian")
plot(density(pm2), main = "Log-transformed")
plot(density(Fixations$Duration), main = "Observed fixation duration")

```

Again, use DHARMa and MuMIn to check which model is best:

```{r}
...

```

How do we interpret these results?

---------

## Social engagement (TylÃ©n et al., 2012)

### Hypothesis 1: Pupil size (absolute, change in pupil size across conditions) is larger in ostensive trials

We want to test the hypothesis that viewers are more emotionally engaged when involved in interaction (~direction & ostensiveness). We operationalize emotional engagement as larger pupil size.

First, we have to extract data from the PyschoPy variable "video" to determine whether the condition is Ostensive vs Non-ostensive and Direct vs Indirect:

```{r}
Fixations <- Fixations %>% 
  mutate(
    Direction = case_when(
      grepl('dir', Fixations$video) ~ "Direct",
      grepl('div', Fixations$video) ~ "Indirect"),
    Ostensiveness = case_when(
      grepl('\\+o', Fixations$video) ~ "Ostensive",
      grepl('-o', Fixations$video) ~ "Non-ostensive")
  )
```

We can now plot the data. We start by looking at the overall values of pupil size. Do they differ based on conditions (Ostensiveness & Direction)? Let's plot the data first and model them afterwards.

```{r}

ggplot(Fixations[Fixations$Task == "Social engagement", ],
       aes(PupilSize, fill = Direction)) +
  geom_density(alpha = .5) +
  facet_wrap(. ~ Ostensiveness)+ggtitle("Direct/Indirect + Non-ostensive/Ostensive")

```

Now model the data. Make sure to include all relevant fixed effects. Make also sure that you account for the fact that different people have different baselines of pupil size.

```{r}
Fixations_SE <- filter(Fixations, Fixations$Task == "Social engagement")

mPupil <- lmer(PupilSize ~ 1 + Ostensiveness * Direction +
       (1|ParticipantID) + (1 | Trial), # Tried Nested with Participant|Trial, a nested random effect with Participant, trial. Looking at data - each participant has multiple rows, but each combination of Participant and Trial also have multiple trials. If you didn't do that, you break the assumption of independence. Changed it to Trial. 
     data = Fixations_SE)

summary(mPupil) # Ostensiveness leads to smaller pupilsize too against our expectation. Positive interaction between the two, best way to interpret would be to plot the data. 
```

We can then look at how pupil size changes over time. This is a good way to account for the fact that the luminosity of the stimuli changes over time.

Plot the data using geom_smooth(method = "gam") in ggplot to see how pupil size changes over time. Remember to only include data from the Social engagement task. Include both Ostensiveness and Direction as variables in the plot. What do we see?

```{r}
ggplot(Fixations_SE, aes(y = PupilSize, x = StartTime, color = Direction))+
  #geom_point()+
  geom_smooth(method = "gam")+
  facet_wrap(.~Ostensiveness)+
  ggtitle("Bigger effect of time in non-ostensive condition. 
Pupils get bigger faster. In Ostensive direction, it's the other way around -
Indirect condition has pupils becoming larger over time. 
Clear main effect of time.
Not what we expected")

# We can change it - because further down we see that there is a main effect of time, showing that pupils get bigger over time. 
ggplot(Fixations_SE, aes(y = PupilSize, x = FixationNo, fill = Ostensiveness))+
  #geom_point()+
  geom_smooth(method = "gam")+
  ggtitle("")

```

Now model the data to see whether we find a main effect of Ostensiveness and an interaction with Direction. Remember the time factor!

```{r}
mPupil2 <- lmer(PupilSize ~ 0 + FixationNo +  Direction*Ostensiveness + 
                  (1 + FixationNo+Direction*Ostensiveness|ParticipantID),
                Fixations_SE)

mPupil2 <- lmer(PupilSize ~ 1 + FixationNo*Direction*Ostensiveness + 
                  (1 | ParticipantID) +
                  (1 | ParticipantID:Trial),
                Fixations_SE)

summary(mPupil2)
```

What do we see?

### Hypothesis 2: Fixations are longer when ostensive + interaction with direction

Fixations may last longer in the Ostensive + Direct condition as a sign that people stare more at faces whenever there is eye contact. In the other conditions, participants may be jumping more back and forth between face and cup, thus resulting in shorter fixations.

Let's start by plotting the data:

```{r}
ggplot(Fixations_SE, aes(x = Duration, color = Direction))+
  #geom_point()+
  geom_density()+
  facet_wrap(.~Ostensiveness)+
  ggtitle("It's the same picture - durations look similar across conditions")


```

The plot doesn't seem to show much difference. What if we model the data?

```{r}
mDuration <- lmer(Duration ~ 0 + Direction*Ostensiveness +
                    (1|ParticipantID)+
                    (1|Trial), data = Fixations_SE)

summary(mDuration)
```

What does the model show? Please interpret the result and look at whether the model is a good fit to the data. Have you taken into account the distribution of the data?
```{r}
plot(density(Fixations_SE$Duration))


# looks lognormal, so change it
mDuration <- glmer(Duration ~ 0 + Direction*Ostensiveness +
                    (1|ParticipantID)+
                    (1|Trial), data = Fixations_SE, family = gaussian(link = "log"))

summary(mDuration)
```

